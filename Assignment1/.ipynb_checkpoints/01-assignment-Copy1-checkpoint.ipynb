{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'twitter_sentiment_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-388c69163f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter_sentiment_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitter_sentiment_data.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('twitter_sentiment_data.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "\n",
    "# def get_tweet_text_from_json(file_path):\n",
    "#     with open(file_path) as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         return data[\"text\"]\n",
    "\n",
    "# def get_events(event_dir):\n",
    "#     event_list = []\n",
    "    \n",
    "#     for event in sorted(os.listdir(event_dir)):\n",
    "#         ###\n",
    "#         # Your answer BEGINS HERE\n",
    "#         ###\n",
    "#         event_text = []\n",
    "#         event_path = os.path.join(event_dir, event)\n",
    "#         for event_type in os.listdir(event_path):\n",
    "#             type_path = os.path.join(event_path, event_type)\n",
    "#             for file in os.listdir(type_path):\n",
    "#                 file_path = os.path.join(type_path, file)\n",
    "#                 event_text.append(get_tweet_text_from_json(file_path))\n",
    "#         event_list.append(event_text)\n",
    "#         ###\n",
    "#         # Your answer ENDS HERE\n",
    "#         ###\n",
    "        \n",
    "#     return event_list\n",
    "    \n",
    "# #a list of events, and each event is a list of tweets (source tweet + reactions)    \n",
    "# rumour_events = get_events(os.path.join(data_dir, \"rumours\"))\n",
    "# nonrumour_events = get_events(os.path.join(data_dir, \"non-rumours\"))\n",
    "\n",
    "# print(\"Number of rumour events =\", len(rumour_events))\n",
    "# print(\"Number of non-rumour events =\", len(nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(rumour_events) == 500)\n",
    "assert(len(nonrumour_events) == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (1.0 mark)\n",
    "\n",
    "**Instructions**: Next we need to preprocess the collected tweets to create a bag-of-words representation. The preprocessing steps required here are: (1) tokenize each tweet into individual word tokens (using NLTK `TweetTokenizer`); and (2) remove stopwords (based on NLTK `stopwords`).\n",
    "\n",
    "**Task**: Complete the `preprocess_events(event)` function. The function takes **a list of events** as input, and returns **a list of preprocessed events**. Each preprocessed event should have a dictionary of words and frequencies.\n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* below for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed rumour events = 500\n",
      "Number of preprocessed non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_events(events):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    post_events = []\n",
    "    for event in events:\n",
    "        text_dict = Counter()\n",
    "        for text in event:\n",
    "            tokenized_text = tt.tokenize(text)\n",
    "            for word in tokenized_text:\n",
    "                if (word.lower not in stopwords):\n",
    "                    text_dict[word] += 1\n",
    "        post_events.append(text_dict)\n",
    "        \n",
    "    return post_events\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "preprocessed_rumour_events = preprocess_events(rumour_events)\n",
    "preprocessed_nonrumour_events = preprocess_events(nonrumour_events)\n",
    "\n",
    "print(\"Number of preprocessed rumour events =\", len(preprocessed_rumour_events))\n",
    "print(\"Number of preprocessed non-rumour events =\", len(preprocessed_nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(preprocessed_rumour_events) == 500)\n",
    "assert(len(preprocessed_nonrumour_events) == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Hashtags (i.e. topic tags which start with #) pose an interesting tokenisation problem because they often include multiple words written without spaces or capitalization. Run the code below to collect all unique hashtags in the preprocessed data. **No implementation is needed.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hashtags = 1829\n"
     ]
    }
   ],
   "source": [
    "def get_all_hashtags(events):\n",
    "    hashtags = set([])\n",
    "    for event in events:\n",
    "        for word, frequency in event.items():\n",
    "            if word.startswith(\"#\"):\n",
    "                hashtags.add(word)\n",
    "    return hashtags\n",
    "\n",
    "hashtags = get_all_hashtags(preprocessed_rumour_events + preprocessed_nonrumour_events)\n",
    "print(\"Number of hashtags =\", len(hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (2.0 mark)\n",
    "\n",
    "**Instructions**: Our task here to tokenize the hashtags, by implementing a reversed version of the MaxMatch algorithm discussed in class, where matching begins at the end of the hashtag and progresses backwards. NLTK has a list of words that you can use for matching, see starter code below. Be careful about efficiency with respect to doing word lookups. One extra challenge you have to deal with is that the provided list of words includes only lemmas: your MaxMatch algorithm should match inflected forms by converting them into lemmas using the NLTK lemmatizer before matching. When lemmatising a word, you also need to provide the part-of-speech tag of the word. You should use `nltk.tag.pos_tag` for doing part-of-speech tagging.\n",
    "\n",
    "Note that the list of words is incomplete, and, if you are unable to make any longer match, your code should default to matching a single letter. Create a new list of tokenized hashtags (this should be a list of lists of strings) and use slicing to print out the last 20 hashtags in the list.\n",
    "\n",
    "For example, given \"#speakup\", the algorithm should produce: \\[\"#\", \"speak\", \"up\"\\]. And note that you do not need to delete the hashtag symbol (\"#\") from the tokenised outputs.\n",
    "\n",
    "**Task**: Complete the `tokenize_hashtags(hashtags)` function by implementing a reversed MaxMatch algorithm. The function takes as input **a set of hashtags**, and returns **a dictionary** where key=\"hashtag\" and value=\"a list of word tokens\".\n",
    "\n",
    "**Check**: Use the assertion statements in *\"For your testing\"* below for the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#dontgiveupthefight', ['#', 'dont', 'give', 'up', 'the', 'fight']), ('#Repent', ['#', 'Repent']), ('#AlQaeda', ['#', 'Al', 'Q', 'ae', 'da']), ('#Kobane', ['#', 'Ko', 'bane']), ('#militarized', ['#', 'militarized']), ('#lulz', ['#', 'l', 'u', 'l', 'z']), ('#Chinada', ['#', 'China', 'da']), ('#MetRules', ['#', 'Met', 'Rules']), ('#RogueCops', ['#', 'Rogue', 'Cops']), ('#message', ['#', 'message']), ('#beards', ['#', 'beards']), ('#prayersforFerguson', ['#', 'prayers', 'f', 'orF', 'erg', 'u', 'son']), ('#BundyRanch', ['#', 'Bundy', 'Ranch']), (\"#Obama's\", ['#', 'O', 'b', 'ama', \"'\", 's']), ('#lindt', ['#', 'lin', 'd', 't']), ('#Daesh', ['#', 'Dae', 'sh']), ('#StayWoke', ['#', 'Stay', 'Woke']), ('#Canada', ['#', 'Canada']), ('#patience', ['#', 'patience']), ('#KeepPhilSafe', ['#', 'Keep', 'Phi', 'l', 'Safe'])]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words()) #a list of words provided by NLTK\n",
    "\n",
    "def convert_tag(tag):\n",
    "    if tag[0] == 'N':\n",
    "        return wordnet.NOUN\n",
    "    elif tag[0] == 'V':\n",
    "        return wordnet.VERB\n",
    "    elif tag[0] == 'J':\n",
    "        return wordnet.ADJ\n",
    "    elif tag[0] == 'R':\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def tokenize_hashtags(hashtags):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    hashtags_dict = {}\n",
    "    for hashtag in hashtags:\n",
    "        tokens = []\n",
    "        \n",
    "        end = 1 # the end of the unwanted substring of the hashtag\n",
    "        stop = len(hashtag) # the end of the current checking substring of the hashtag\n",
    "        found_len = 1 # \"#\" is always here\n",
    "        while(found_len < len(hashtag)):\n",
    "            word_list = [hashtag[1:end], hashtag[end:stop]]\n",
    "            word_list = [word for word in word_list if word != ''] # remove '' for pos_tag\n",
    "            wl_copy = [word.lower() for word in word_list] # change to lowercases\n",
    "        \n",
    "            pos_tags = nltk.pos_tag(wl_copy) # instead of pass only 1 word at a time, split the hashtag into 2 words and pass all words in for a better tagging\n",
    "            word, tag = pos_tags[-1] # reverse MaxMatch, so we need to pick the latter word\n",
    "            lemma = lemmatizer.lemmatize(word, convert_tag(tag))\n",
    "            if (lemma in words):\n",
    "                end = 1\n",
    "                stop -= len(word)\n",
    "                found_len += len(word)\n",
    "                \n",
    "                tokens = [word_list[-1]] + tokens\n",
    "            else:\n",
    "                end += 1\n",
    "                if (end == len(hashtag)):\n",
    "                    end = 1\n",
    "                    stop -= 1\n",
    "                    found_len += 1\n",
    "                    tokens = [hashtag[stop]] + tokens\n",
    "        hashtags_dict[hashtag] = [\"#\"] + tokens\n",
    "    return hashtags_dict\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "    \n",
    "    \n",
    "tokenized_hashtags = tokenize_hashtags(hashtags)\n",
    "\n",
    "print(list(tokenized_hashtags.items())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For your testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(tokenized_hashtags) == len(hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (1.0 mark)\n",
    "\n",
    "**Instructions**: Now that we have the tokenized hashtags, we need to go back and update the bag-of-words representation for each event.\n",
    "\n",
    "**Task**: Complete the ``update_event_bow(events)`` function. The function takes **a list of preprocessed events**, and for each event, it looks for every hashtag it has and updates the bag-of-words dictionary with the tokenized hashtag tokens. Note: you do not need to delete the counts of the original hashtags when updating the bag-of-words (e.g., if a document has \"#speakup\":2 in its bag-of-words representation, you do not need to delete this hashtag and its counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of preprocessed rumour events = 500\n",
      "Number of preprocessed non-rumour events = 1000\n"
     ]
    }
   ],
   "source": [
    "def update_event_bow(events):\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    for event in events:\n",
    "        for hashtag, tokens in tokenized_hashtags.items():\n",
    "            if hashtag in event:\n",
    "                for token in tokens:\n",
    "                    event[token] += 1\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "            \n",
    "update_event_bow(preprocessed_rumour_events)\n",
    "update_event_bow(preprocessed_nonrumour_events)\n",
    "\n",
    "print(\"Number of preprocessed rumour events =\", len(preprocessed_rumour_events))\n",
    "print(\"Number of preprocessed non-rumour events =\", len(preprocessed_nonrumour_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (1.0 mark)\n",
    "\n",
    "**Instructions**: Here we are interested to do text classification, to predict, given a tweet and its reactions, whether it is a rumour or not. The task here is to create training, development and test partitions from the preprocessed events and convert the bag-of-words representation into feature vectors.\n",
    "\n",
    "**Task**: Using scikit-learn, create training, development and test partitions with a 60%/20%/20% ratio. Remember to preserve the ratio of rumour/non-rumour events for all your partitions. Next, turn the bag-of-words dictionary of each event into a feature vector, using scikit-learn `DictVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 28047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "X_train_rumour, X_test_rumour = train_test_split(preprocessed_rumour_events, test_size=0.2)\n",
    "X_train_rumour, X_dev_rumour = train_test_split(X_train_rumour, test_size=0.25)\n",
    "y_train_rumour = [1 for i in range(len(X_train_rumour))]\n",
    "y_test_rumour = [1 for i in range(len(X_test_rumour))]\n",
    "y_dev_rumour = [1 for i in range(len(X_dev_rumour))]\n",
    "\n",
    "X_train_nrumour, X_test_nrumour = train_test_split(preprocessed_nonrumour_events, test_size=0.2)\n",
    "X_train_nrumour, X_dev_nrumour = train_test_split(X_train_nrumour, test_size=0.25)\n",
    "y_train_nrumour = [0 for i in range(len(X_train_nrumour))]\n",
    "y_test_nrumour = [0 for i in range(len(X_test_nrumour))]\n",
    "y_dev_nrumour = [0 for i in range(len(X_dev_nrumour))]\n",
    "\n",
    "X_train = X_train_rumour + X_train_nrumour\n",
    "X_test = X_test_rumour + X_test_nrumour\n",
    "X_dev = X_dev_rumour + X_dev_nrumour\n",
    "\n",
    "y_train = y_train_rumour + y_train_nrumour\n",
    "y_test = y_test_rumour + y_test_nrumour\n",
    "y_dev = y_dev_rumour + y_dev_nrumour\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_dev = vectorizer.transform(X_dev)\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(\"Vocabulary size =\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (2.0 mark)\n",
    "\n",
    "**Instructions**: Now, let's build some classifiers. Here, we'll be comparing Naive Bayes and Logistic Regression. For each, you need to first find a good value for their main regularisation (hyper)parameters, which you should identify using the scikit-learn docs or other resources. Use the development set you created for this tuning process; do **not** use cross-validation in the training set, or involve the test set in any way. You don't need to show all your work, but you do need to print out the accuracy with enough different settings to strongly suggest you have found an optimal or near-optimal choice. We should not need to look at your code to interpret the output.\n",
    "\n",
    "**Task**: Implement two text classifiers: Naive Bayes and Logistic Regression. Tune the hyper-parameters of these classifiers and print the task performance for different hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiachengye/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 accuracy with corresponding alpha values are: \n",
      "Accuracy is: 0.8066666666666666, alpha value is: 0.9\n",
      "Accuracy is: 0.8066666666666666, alpha value is: 0.91\n",
      "Accuracy is: 0.8066666666666666, alpha value is: 0.92\n",
      "Accuracy is: 0.8066666666666666, alpha value is: 0.94\n",
      "Accuracy is: 0.8066666666666666, alpha value is: 0.95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiachengye/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 accuracy with corresponding max_iter and C are: \n",
      "{'max_iter': 1000, 'C': 0.1, 'Accuracy': 0.8666666666666667}\n",
      "{'max_iter': 5000, 'C': 0.1, 'Accuracy': 0.8666666666666667}\n",
      "{'max_iter': 10000, 'C': 0.1, 'Accuracy': 0.8666666666666667}\n",
      "{'max_iter': 1000, 'C': 0.01, 'Accuracy': 0.8433333333333334}\n",
      "{'max_iter': 5000, 'C': 0.01, 'Accuracy': 0.8433333333333334}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "NB_result = []\n",
    "NB_para = [x/100 for x in range(101)]\n",
    "for para in NB_para:\n",
    "    NB_clf = MultinomialNB(alpha = para)\n",
    "    NB_clf.fit(X_train, y_train)\n",
    "    score = NB_clf.score(X_dev, y_dev)\n",
    "    NB_result.append((score, para))\n",
    "NB_result = sorted(NB_result, key=lambda x:x[0], reverse = True)\n",
    "print(\"Top 5 accuracy with corresponding alpha values are: \")\n",
    "for i in range(5):\n",
    "    print(f'Accuracy is: {NB_result[i][0]}, alpha value is: {NB_result[i][1]}')\n",
    "    \n",
    "print()\n",
    "\n",
    "best_solve = ''\n",
    "best_max_iter = 0\n",
    "best_C = 0\n",
    "best_score = 0\n",
    "max_iter = [1000, 5000, 10000]\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "LR_result = []\n",
    "for i in max_iter:\n",
    "    for c in C:\n",
    "        lr_clf = LogisticRegression(max_iter = i, C = c)\n",
    "        lr_clf.fit(X_train, y_train)\n",
    "        score = lr_clf.score(X_dev, y_dev)\n",
    "        LR_result.append({\"max_iter\": i, \"C\": c, \"Accuracy\": score})\n",
    "LR_result = sorted(LR_result, key=lambda x:x['Accuracy'], reverse = True)\n",
    "print(\"Top 5 accuracy with corresponding max_iter and C are: \")\n",
    "for i in range(5):\n",
    "    print(LR_result[i])\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (1.0 mark)\n",
    "\n",
    "**Instructions**: Using the best settings you have found, compare the two classifiers based on performance in the test set. Print out both accuracy and macro-averaged F-score for each classifier. Be sure to label your output.\n",
    "\n",
    "**Task**: Compute test performance in terms of accuracy and macro-averaged F-score for both Naive Bayes and Logistic Regression, using optimal hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for MultinomialNB is: 0.7866666666666666\n",
      "F-score for MultinomialNB is: 0.6444444444444445\n",
      "The alpha value used is: 0.9\n",
      "\n",
      "Accuracy for Logistic Regression is: 0.7866666666666666\n",
      "F-score for Logistic Regression is: 0.632183908045977\n",
      "The max_iter and C used are: 1000 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiachengye/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "NB_clf = MultinomialNB(alpha = NB_result[0][1])\n",
    "NB_clf.fit(X_train, y_train)\n",
    "predict = NB_clf.predict(X_test)\n",
    "print(\"Accuracy for MultinomialNB is: \" + str(accuracy_score(predict, y_test)))\n",
    "print(\"F-score for MultinomialNB is: \" + str(f1_score(predict, y_test)))\n",
    "print(\"The alpha value used is: \" + str(NB_result[0][1]))\n",
    "\n",
    "print()\n",
    "\n",
    "best_para = LR_result[0]\n",
    "LR_clf = LogisticRegression(max_iter = best_para['max_iter'], C = best_para['C'])\n",
    "LR_clf.fit(X_train, y_train)\n",
    "predict = LR_clf.predict(X_test)\n",
    "print(\"Accuracy for Logistic Regression is: \" + str(accuracy_score(predict, y_test)))\n",
    "print(\"F-score for Logistic Regression is: \" + str(f1_score(predict, y_test)))\n",
    "print(\"The max_iter and C used are: \"+ str(best_para['max_iter']) + \" \" + str(best_para['C']))\n",
    "\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
